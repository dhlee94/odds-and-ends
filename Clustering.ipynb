{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "def fit_pca(img, pca):\n",
    "    return pca.fit_transform(img)\n",
    "\n",
    "def kmeans_clustering(number_clusters, random_state):\n",
    "    return KMeans(n_clusters=number_clusters, random_state=random_state)\n",
    "\n",
    "def dbscan_clustering(min_samples=5):\n",
    "    return DBSCAN(min_samples=min_samples)\n",
    "\n",
    "def normalization(data):\n",
    "    scaler = StandardScaler()\n",
    "    return scaler.fit_transform(data)\n",
    "\n",
    "def tsne_visualization(n_components=2, perplexity=30.0, learning_rate='pca', verbose=1):\n",
    "    #return TSNE(n_components=n_components, perplexity=perplexity, learning_rate=learning_rate, verbose=verbose)\n",
    "    return TSNE(n_components=n_components, perplexity=perplexity, verbose=verbose)\n",
    "\n",
    "def clustering_result(kmeans):\n",
    "    image_cluster_dict = {}\n",
    "    for i, m in enumerate(kmeans):\n",
    "        image_cluster_dict[f'{m}'] = 0 \n",
    "    for i, m in enumerate(kmeans):\n",
    "        image_cluster_dict[f'{m}'] += 1\n",
    "    return image_cluster_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = importlib.import_module('torchvision.models')\n",
    "model = mod.resnet18(pretrained=True)\n",
    "model.fc = nn.Identity()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    min_value = torch.min(data)\n",
    "    max_value = torch.max(data)\n",
    "    return (data-min_value)/(max_value-min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'D:/kaggle-Fruit-Dataset'\n",
    "folder_lists = [os.path.join(path, folder) for folder in os.listdir(path)]\n",
    "image_lists = []\n",
    "for folder in folder_lists[:3]:\n",
    "    image_lists.extend([os.path.join(folder, name) for name in os.listdir(folder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "data_lists = []\n",
    "for image_path in image_lists:\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    data_lists.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(image_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "input = []\n",
    "result = []\n",
    "for idx, data in enumerate(data_lists):\n",
    "    tmp = torch.FloatTensor(data)\n",
    "    tmp = normalize(tmp)\n",
    "    input.append(tmp.permute(2, 0, 1))\n",
    "    if len(input)==batch_size or idx==len(data_lists)-1:\n",
    "        input = torch.stack(input, dim=0)\n",
    "        result.extend(model(input).detach().cpu().numpy())\n",
    "        input = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.stack(result, axis=0)\n",
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=200)\n",
    "pca_result = fit_pca(result, pca)\n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "norm_result = normalization(pca_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "#distortions = []\n",
    "#for i in range(1, 50):\n",
    "#    kmeans = kmeans_clustering(number_clusters=i, random_state=1)\n",
    "#    kmeans.fit(norm_result)\n",
    "#    distortions.append(kmeans.inertia_) \n",
    "#plt.plot(range(1, 50), distortions, marker='o')\n",
    "#plt.xlabel('Number of clusters')\n",
    "#plt.ylabel('Distortion')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = kmeans_clustering(number_clusters=3, random_state=1)\n",
    "clustering = kmeans.fit_predict(norm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_dict = clustering_result(clustering)\n",
    "print(cluster_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = tsne_visualization()\n",
    "tsne_result = tsne.fit_transform(norm_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.scatterplot(x=tsne_result[:, 0], y=tsne_result[:, 1], hue=clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
