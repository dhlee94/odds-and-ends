{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = importlib.import_module('torchvision.models')\n",
    "model = mod.resnet18(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(data):\n",
    "    min_value = torch.min(data)\n",
    "    max_value = torch.max(data)\n",
    "    return (data-min_value)/(max_value-min_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "path = 'D:/kaggle-Fruit-Dataset'\n",
    "folder_lists = [os.path.join(path, folder) for folder in os.listdir(path)]\n",
    "image_lists = []\n",
    "for folder in folder_lists[:3]:\n",
    "    image_lists.extend([os.path.join(folder, name) for name in os.listdir(folder)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "data_lists = []\n",
    "for image_path in image_lists:\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    data_lists.append(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from pytorch_grad_cam import GradCAM\n",
    "\n",
    "print(model.layer4[-1])\n",
    "targets = [ClassifierOutputTarget(0)]\n",
    "target_layers = [model.layer4[-1].conv2]\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_result = []\n",
    "for idx, data in enumerate(data_lists):\n",
    "    tmp = torch.FloatTensor(data)\n",
    "    tmp = normalize(tmp)\n",
    "    input = tmp.permute(2, 0, 1).unsqueeze(0)\n",
    "    result = cam(input_tensor=input, targets=targets)\n",
    "    whole_result.append(result)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ldh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
